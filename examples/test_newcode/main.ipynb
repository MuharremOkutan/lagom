{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Import lagom\n",
    "# Not useful once lagom is installed\n",
    "import sys\n",
    "sys.path.append('/home/zuo/Code/lagom/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lagom.envs.vec_env import DummyVecEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use functiontools.partial to set make_env function without argument but internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.99818915,  0.06015327,  0.99840103, -0.05652779,  0.0641808 ,\n",
       "         0.02995456],\n",
       "       [ 0.99792521,  0.06438386,  0.99739941,  0.0720723 ,  0.08908737,\n",
       "         0.01363955]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from lagom.envs import GymEnv\n",
    "\n",
    "def make_env():\n",
    "    env = gym.make('Acrobot-v1')\n",
    "    \n",
    "    return GymEnv(env)\n",
    "\n",
    "env = DummyVecEnv([make_env, make_env])\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "\n",
    "class DummyVecEnv(VecEnv):\n",
    "    def __init__(self, env_fns):\n",
    "        self.envs = [fn() for fn in env_fns]\n",
    "        env = self.envs[0]\n",
    "        super().__init__(len(env_fns), env.observation_space, env.action_space)\n",
    "\n",
    "        obs_spaces = self.observation_space.spaces if isinstance(self.observation_space, gym.spaces.Tuple) else (self.observation_space,)\n",
    "        self.buf_obs = [np.zeros((self.num_envs,) + tuple(s.shape), s.dtype) for s in obs_spaces]\n",
    "        self.buf_dones = np.zeros((self.num_envs,), dtype=np.bool)\n",
    "        self.buf_rews  = np.zeros((self.num_envs,), dtype=np.float32)\n",
    "        self.buf_infos = [{} for _ in range(self.num_envs)]\n",
    "        self.actions = None\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        self.actions = actions\n",
    "\n",
    "    def step_wait(self):\n",
    "        for i in range(self.num_envs):\n",
    "            obs_tuple, self.buf_rews[i], self.buf_dones[i], self.buf_infos[i] = self.envs[i].step(self.actions[i])\n",
    "            if self.buf_dones[i]:\n",
    "                obs_tuple = self.envs[i].reset()\n",
    "            if isinstance(obs_tuple, (tuple, list)):\n",
    "                for t,x in enumerate(obs_tuple):\n",
    "                    self.buf_obs[t][i] = x\n",
    "            else:\n",
    "                self.buf_obs[0][i] = obs_tuple\n",
    "        return (self._obs_from_buf(), np.copy(self.buf_rews), np.copy(self.buf_dones),\n",
    "                self.buf_infos.copy())\n",
    "\n",
    "    def reset(self):\n",
    "        for i in range(self.num_envs):\n",
    "            obs_tuple = self.envs[i].reset()\n",
    "            if isinstance(obs_tuple, (tuple, list)):\n",
    "                for t,x in enumerate(obs_tuple):\n",
    "                    self.buf_obs[t][i] = x\n",
    "            else:\n",
    "                self.buf_obs[0][i] = obs_tuple\n",
    "        return self._obs_from_buf()\n",
    "\n",
    "    def close(self):\n",
    "        return\n",
    "\n",
    "    def _obs_from_buf(self):\n",
    "        if len(self.buf_obs) == 1:\n",
    "            return np.copy(self.buf_obs[0])\n",
    "        else:\n",
    "            return tuple(np.copy(x) for x in self.buf_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Process  # easier code than threading\n",
    "from multiprocessing import Pipe  # Much faster than Queue\n",
    "\n",
    "\n",
    "class CloudpickleWrapper(object):\n",
    "    \"\"\"\n",
    "    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n",
    "    \"\"\"\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.x()\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        import cloudpickle\n",
    "        return cloudpickle.dumps(self.x)\n",
    "    def __setstate__(self, ob):\n",
    "        import pickle\n",
    "        self.x = pickle.loads(ob)\n",
    "\n",
    "\n",
    "def worker(child_conn, parent_conn, make_env):\n",
    "    parent_conn.close()\n",
    "    # Create an environment\n",
    "    env = make_env()\n",
    "    \n",
    "    while True:\n",
    "        cmd, data = child_conn.recv()\n",
    "        if cmd == 'step':\n",
    "            obs, reward, done, info = env.step(data)\n",
    "            if done:\n",
    "                obs = env.reset()  # TODO: why reset\n",
    "            child_conn.send([obs, reward, done, info])\n",
    "        elif cmd == 'reset':\n",
    "            obs = env.reset()\n",
    "            child_conn.send(obs)\n",
    "        elif cmd == 'reset_task':\n",
    "            obs = env.reset_task()\n",
    "            child_conn.send(obs)\n",
    "        elif cmd == 'close':\n",
    "            child_conn.close()\n",
    "            break\n",
    "        elif cmd == 'get_spaces':\n",
    "            child_conn.send([env.observation_space, env.action_space])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "class SubprocVecEnv(VecEnv):\n",
    "    \"\"\"\n",
    "    Run a list of environment in subprocesses\n",
    "    \"\"\"\n",
    "    def __init__(self, list_make_env):\n",
    "        self.waiting = False\n",
    "        self.closed = False\n",
    "        self.num_envs = len(list_make_env)\n",
    "        self.parent_conns, self.child_conns = zip(*[Pipe() for _ in range(self.num_envs)])\n",
    "        self.processes = []\n",
    "        for parent_conn, child_conn, make_env in zip(self.parent_conns, self.child_conns, list_make_env):\n",
    "            self.processes.append(Process(target=worker, args=[child_conn, parent_conn, CloudpickleWrapper(make_env)]))  # TODO: CloudpickleWrapper make_env\n",
    "        for process in self.processes:\n",
    "            process.daemon = True  # if the main process crashes, we should not cause things to hang\n",
    "            process.start()\n",
    "        for conn in self.child_conns:\n",
    "            conn.close()\n",
    "        \n",
    "        # Obtain observation and action spaces\n",
    "        self.parent_conns[0].send(['get_spaces', None])\n",
    "        observation_space, action_space = self.parent_conns[0].recv()\n",
    "        super().__init__(self.num_envs, observation_space, action_space)\n",
    "        \n",
    "    def step_asyn(self, actions):\n",
    "        for parent_conn, action in zip(self.parent_conns, actions):\n",
    "            parent_conn.send(['step', action])\n",
    "            \n",
    "        self.waiting = True\n",
    "        \n",
    "    def step_wait(self):\n",
    "        observations, rewards, dones, infos = zip(*[parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "        self.waiting = False\n",
    "        return np.stack(observations), np.stack(rewards), np.stack(dones), infos\n",
    "    \n",
    "    def reset(self):\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['reset', None])\n",
    "        return np.stack([parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "    \n",
    "    def reset_task(self):\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['reset_task', None])\n",
    "        return np.stack([parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "    \n",
    "    def close(self):\n",
    "        if self.closed:\n",
    "            return\n",
    "        if self.waiting:\n",
    "            for parent_conn in self.parent_conns:\n",
    "                parent_conn.recv()\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['close', None])\n",
    "        for process in self.processes:\n",
    "            process.join()\n",
    "        self.closed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lagom.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (Conv 1): Conv2d(3, 4, kernel_size=(3, 3), stride=(3, 3))\n",
      "    (Conv 2): Conv2d(4, 4, kernel_size=(3, 3), stride=(3, 3))\n",
      "    (Conv 3): Conv2d(4, 4, kernel_size=(3, 3), stride=(3, 3))\n",
      "  )\n",
      "  (MLP): MLP(\n",
      "    (hidden_layers): Sequential(\n",
      "      (FC 1): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (FC 2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    )\n",
      "    (output_layer): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "conv = CNN(3, [128, 128], [4, 4, 4], [3, 3, 3], [3, 3, 3], [0, 0, 0], F.relu, [32, 16], F.relu, 2, None)\n",
    "\n",
    "x = torch.zeros(20, 3, 128, 128)\n",
    "print(conv)\n",
    "conv(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from .MLP import MLP\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional neural networks, from DeepMind Nature paper. \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_channel, \n",
    "                 input_shape,\n",
    "                 conv_kernels,\n",
    "                 conv_kernel_sizes,\n",
    "                 conv_strides, \n",
    "                 conv_pads, \n",
    "                 conv_nonlinearity, \n",
    "                 hidden_sizes=None, \n",
    "                 hidden_nonlinearity=None, \n",
    "                 output_dim=None, \n",
    "                 output_nonlinearity=None):\n",
    "        \"\"\"\n",
    "        Set up CNN with configurations. \n",
    "        \n",
    "        Args:\n",
    "            input_channel (int): the number of channels of the input, e.g. color channel\n",
    "            input_shape (list): [Height, Width] of the input, to calculate the \n",
    "            conv_kernels (list): a list of number of kernels (filters or feature maps), for each convolutional layer. \n",
    "            conv_kernel_sizes (list): a list of kernel sizes, [int or tuple], for each convolutional layer. \n",
    "            conv_strides (list): a list of strides, for each convolutional layer. \n",
    "            conv_pads (list): a list of paddings, for each convolutional layer. \n",
    "            conv_nonlinearity (nn.functional): nonlinearity for convolutional layers\n",
    "            hidden_sizes (list): a list of sizes for hidden layers\n",
    "            hidden_nonlinearity (nn.functional): nonlinearity for hidden layers\n",
    "            output_dim (int): output dimension\n",
    "                                If None, then no output layer to be generated (useful if output has different heads)\n",
    "            output_nonlinearity (nn.functional): nonlinearity for output layer\n",
    "                                If None, then no output nonlinearity\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_channel = input_channel\n",
    "        self.input_shape = input_shape\n",
    "        self.conv_kernels = conv_kernels\n",
    "        self.conv_kernel_sizes = conv_kernel_sizes\n",
    "        self.conv_strides = conv_strides\n",
    "        self.conv_pads = conv_pads \n",
    "        self.conv_nonlinearity = conv_nonlinearity\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.hidden_nonlinearity = hidden_nonlinearity\n",
    "        self.output_dim = output_dim\n",
    "        self.output_nonlinearity = output_nonlinearity\n",
    "        \n",
    "        # Iteratively build convolutional layers\n",
    "        # Should use nn.Sequential, otherwise cannot be recognized\n",
    "        self.conv_layers = nn.Sequential()\n",
    "        # Augment the input channel to the list of conv_kernels\n",
    "        kernels = [self.input_channel] + self.conv_kernels\n",
    "        for i in range(len(self.conv_kernels)):\n",
    "            in_channels = kernels[i]\n",
    "            out_channels = kernels[i+1]\n",
    "            conv = nn.Conv2d(in_channels=in_channels,\n",
    "                             out_channels=out_channels,\n",
    "                             kernel_size=self.conv_kernel_sizes[i], \n",
    "                             stride=self.conv_strides[i], \n",
    "                             padding=self.conv_pads[i])\n",
    "            self.conv_layers.add_module(f'Conv {i+1}', conv)\n",
    "\n",
    "        # MLP\n",
    "        if self.hidden_sizes is not None:\n",
    "            # Temporary forward pass to determine MLP input_dim\n",
    "            input_dim = self._conv_out_dim()\n",
    "            # Create MLP\n",
    "            self.MLP = MLP(input_dim=input_dim,\n",
    "                           hidden_sizes=self.hidden_sizes, \n",
    "                           hidden_nonlinearity=self.hidden_nonlinearity,\n",
    "                           output_dim=self.output_dim, \n",
    "                           output_nonlinearity=self.output_nonlinearity)\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self._init_params()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self._conv_forward(x)\n",
    "        \n",
    "        if self.hidden_sizes is not None:\n",
    "            # Flatten the tensors for MLP\n",
    "            x = x.view(x.size(0), -1)\n",
    "            \n",
    "            # Forward pass through MLP\n",
    "            x = self.MLP(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def _conv_forward(self, x):\n",
    "        for conv in self.conv_layers:\n",
    "            x = self.conv_nonlinearity(conv(x))\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def _conv_out_dim(self):\n",
    "        x = torch.zeros(1, self.input_channel, *self.input_shape)\n",
    "        x = self._conv_forward(x)\n",
    "        out_dim = x.view(1, -1).size(1)\n",
    "        \n",
    "        return out_dim\n",
    "        \n",
    "    def _init_params(self):\n",
    "        \"\"\"\n",
    "        Initialize the parameters for convolutional layers, filter weights and biases\n",
    "        \n",
    "        Orthogonal weight initialization and zero bias initialization\n",
    "        \"\"\"\n",
    "        # TODO: more flexible initialization API\n",
    "        # Iterate over all convolutional layers\n",
    "        for conv in self.conv_layers:\n",
    "            # Calculate gain for the nonlinearity\n",
    "            gain = nn.init.calculate_gain(self.conv_nonlinearity.__name__)\n",
    "            # Weight initialization\n",
    "            nn.init.orthogonal_(conv.weight, gain=gain)\n",
    "            # Bias initialization\n",
    "            nn.init.constant_(conv.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 2, [5, 5])\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "T = 20\n",
    "L = 1000\n",
    "N = 100\n",
    "\n",
    "x = np.empty((N, L), 'int64')\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "data = np.sin(x/T).astype('float32')\n",
    "\n",
    "\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 51)\n",
    "        self.linear = nn.Linear(51, 1)\n",
    "        \n",
    "    def forward(self, x, future=0):\n",
    "        outputs = []\n",
    "        batch_size, x_size = x.size()\n",
    "        \n",
    "        h_t = torch.zeros(batch_size, 51)\n",
    "        c_t = torch.zeros(batch_size, 51)\n",
    "        h_t_2 = torch.zeros(batch_size, 51)\n",
    "        c_t_2 = torch.zeros(batch_size, 51)\n",
    "        \n",
    "        chunks = x.chunk(x_size, dim=1)\n",
    "        \n",
    "        for x_t in chunks:\n",
    "            h_t, c_t = self.lstm1(x_t, (h_t, c_t))\n",
    "            h_t_2, c_t_2 = self.lstm2(h_t, (h_t_2, c_t_2))\n",
    "            \n",
    "            output = self.linear(h_t_2)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        for _ in range(future):  # if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t_2, c_t_2 = self.lstm2(h_t, (h_t_2, c_t_2))\n",
    "            \n",
    "            output = self.linear(h_t_2)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1).squeeze(2)\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input = torch.from_numpy(data[3:, :-1])\n",
    "    target = torch.from_numpy(data[3:, 1:])\n",
    "    test_input = torch.from_numpy(data[:3, :-1])\n",
    "    test_target = torch.from_numpy(data[:3, 1:])\n",
    "\n",
    "    seq = Sequence()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Use LBFGS since we load whole data to train\n",
    "    optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n",
    "\n",
    "    for i in range(2):\n",
    "        print(f'STEP: {i}')\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            out = seq(input)\n",
    "            loss = criterion(out, target)\n",
    "            print(f'Loss: {loss.item()}')\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # Prediction\n",
    "        future = 1000\n",
    "        pred = seq(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-future], test_target)\n",
    "        print(f'Test loss: {loss.item()}')\n",
    "        y = pred.data.numpy()\n",
    "\n",
    "        # Drawing\n",
    "        plt.figure(figsize=(30, 10))\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        def draw(yi, color):\n",
    "            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth=2.0)\n",
    "            plt.plot(np.arange(input.size(1), input.size(1)+future), yi[input.size(1):], color + ':', linewidth=2.0)\n",
    "        draw(y[0], 'r')\n",
    "        draw(y[1], 'g')\n",
    "        draw(y[2], 'b')\n",
    "        \n",
    "        plt.savefig(f'logs/{i}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
