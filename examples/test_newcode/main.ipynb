{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Import lagom\n",
    "# Not useful once lagom is installed\n",
    "import sys\n",
    "sys.path.append('/home/zuo/Code/lagom/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use functiontools.partial to set make_env function without argument but internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'numpy' from '/home/zuo/anaconda3/envs/RL_server/lib/python3.6/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.swapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Process  # easier code than threading\n",
    "from multiprocessing import Pipe  # Much faster than Queue\n",
    "\n",
    "\n",
    "class CloudpickleWrapper(object):\n",
    "    \"\"\"\n",
    "    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n",
    "    \"\"\"\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.x()\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        import cloudpickle\n",
    "        return cloudpickle.dumps(self.x)\n",
    "    def __setstate__(self, ob):\n",
    "        import pickle\n",
    "        self.x = pickle.loads(ob)\n",
    "\n",
    "\n",
    "def worker(child_conn, parent_conn, make_env):\n",
    "    parent_conn.close()\n",
    "    # Create an environment\n",
    "    env = make_env()\n",
    "    \n",
    "    while True:\n",
    "        cmd, data = child_conn.recv()\n",
    "        if cmd == 'step':\n",
    "            obs, reward, done, info = env.step(data)\n",
    "            if done:\n",
    "                obs = env.reset()  # TODO: why reset\n",
    "            child_conn.send([obs, reward, done, info])\n",
    "        elif cmd == 'reset':\n",
    "            obs = env.reset()\n",
    "            child_conn.send(obs)\n",
    "        elif cmd == 'reset_task':\n",
    "            obs = env.reset_task()\n",
    "            child_conn.send(obs)\n",
    "        elif cmd == 'close':\n",
    "            child_conn.close()\n",
    "            break\n",
    "        elif cmd == 'get_spaces':\n",
    "            child_conn.send([env.observation_space, env.action_space])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "class SubprocVecEnv(VecEnv):\n",
    "    \"\"\"\n",
    "    Run a list of environment in subprocesses\n",
    "    \"\"\"\n",
    "    def __init__(self, list_make_env):\n",
    "        self.waiting = False\n",
    "        self.closed = False\n",
    "        self.num_envs = len(list_make_env)\n",
    "        self.parent_conns, self.child_conns = zip(*[Pipe() for _ in range(self.num_envs)])\n",
    "        self.processes = []\n",
    "        for parent_conn, child_conn, make_env in zip(self.parent_conns, self.child_conns, list_make_env):\n",
    "            self.processes.append(Process(target=worker, args=[child_conn, parent_conn, CloudpickleWrapper(make_env)]))  # TODO: CloudpickleWrapper make_env\n",
    "        for process in self.processes:\n",
    "            process.daemon = True  # if the main process crashes, we should not cause things to hang\n",
    "            process.start()\n",
    "        for conn in self.child_conns:\n",
    "            conn.close()\n",
    "        \n",
    "        # Obtain observation and action spaces\n",
    "        self.parent_conns[0].send(['get_spaces', None])\n",
    "        observation_space, action_space = self.parent_conns[0].recv()\n",
    "        super().__init__(self.num_envs, observation_space, action_space)\n",
    "        \n",
    "    def step_asyn(self, actions):\n",
    "        for parent_conn, action in zip(self.parent_conns, actions):\n",
    "            parent_conn.send(['step', action])\n",
    "            \n",
    "        self.waiting = True\n",
    "        \n",
    "    def step_wait(self):\n",
    "        observations, rewards, dones, infos = zip(*[parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "        self.waiting = False\n",
    "        return np.stack(observations), np.stack(rewards), np.stack(dones), infos\n",
    "    \n",
    "    def reset(self):\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['reset', None])\n",
    "        return np.stack([parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "    \n",
    "    def reset_task(self):\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['reset_task', None])\n",
    "        return np.stack([parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "    \n",
    "    def close(self):\n",
    "        if self.closed:\n",
    "            return\n",
    "        if self.waiting:\n",
    "            for parent_conn in self.parent_conns:\n",
    "                parent_conn.recv()\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['close', None])\n",
    "        for process in self.processes:\n",
    "            process.join()\n",
    "        self.closed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "T = 20\n",
    "L = 1000\n",
    "N = 100\n",
    "\n",
    "x = np.empty((N, L), 'int64')\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "data = np.sin(x/T).astype('float32')\n",
    "\n",
    "\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 51)\n",
    "        self.linear = nn.Linear(51, 1)\n",
    "        \n",
    "    def forward(self, x, future=0):\n",
    "        outputs = []\n",
    "        batch_size, x_size = x.size()\n",
    "        \n",
    "        h_t = torch.zeros(batch_size, 51)\n",
    "        c_t = torch.zeros(batch_size, 51)\n",
    "        h_t_2 = torch.zeros(batch_size, 51)\n",
    "        c_t_2 = torch.zeros(batch_size, 51)\n",
    "        \n",
    "        chunks = x.chunk(x_size, dim=1)\n",
    "        \n",
    "        for x_t in chunks:\n",
    "            h_t, c_t = self.lstm1(x_t, (h_t, c_t))\n",
    "            h_t_2, c_t_2 = self.lstm2(h_t, (h_t_2, c_t_2))\n",
    "            \n",
    "            output = self.linear(h_t_2)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        for _ in range(future):  # if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t_2, c_t_2 = self.lstm2(h_t, (h_t_2, c_t_2))\n",
    "            \n",
    "            output = self.linear(h_t_2)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1).squeeze(2)\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input = torch.from_numpy(data[3:, :-1])\n",
    "    target = torch.from_numpy(data[3:, 1:])\n",
    "    test_input = torch.from_numpy(data[:3, :-1])\n",
    "    test_target = torch.from_numpy(data[:3, 1:])\n",
    "\n",
    "    seq = Sequence()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Use LBFGS since we load whole data to train\n",
    "    optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n",
    "\n",
    "    for i in range(2):\n",
    "        print(f'STEP: {i}')\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            out = seq(input)\n",
    "            loss = criterion(out, target)\n",
    "            print(f'Loss: {loss.item()}')\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # Prediction\n",
    "        future = 1000\n",
    "        pred = seq(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-future], test_target)\n",
    "        print(f'Test loss: {loss.item()}')\n",
    "        y = pred.data.numpy()\n",
    "\n",
    "        # Drawing\n",
    "        plt.figure(figsize=(30, 10))\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        def draw(yi, color):\n",
    "            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth=2.0)\n",
    "            plt.plot(np.arange(input.size(1), input.size(1)+future), yi[input.size(1):], color + ':', linewidth=2.0)\n",
    "        draw(y[0], 'r')\n",
    "        draw(y[1], 'g')\n",
    "        draw(y[2], 'b')\n",
    "        \n",
    "        plt.savefig(f'logs/{i}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Import lagom\n",
    "# Not useful once lagom is installed\n",
    "import sys\n",
    "sys.path.append('/home/zuo/Code/lagom/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from lagom.core.networks import MLP\n",
    "\n",
    "\n",
    "class MDN(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines the mixture density networks using isotropic Gaussian densities and MLP. \n",
    "    \n",
    "    The network receives input tensor and outputs parameters for a mixture of Gaussian distributions. \n",
    "    i.e. mixing coefficients, means and variances. \n",
    "    \n",
    "    Specifically, their dimensions are following, given N is batch size, K is the number of densities\n",
    "    and D is the output dimension\n",
    "    \n",
    "    - mixing coefficients: [N, K]\n",
    "    - mean: [N, K, D]\n",
    "    - variance: [N, K, D]\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 output_dim, \n",
    "                 num_densities, \n",
    "                 hidden_sizes, \n",
    "                 hidden_nonlinearity):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): the number of dimensions of input tensor\n",
    "            output_dim (int): the number of dimensions of output tensor\n",
    "            num_densities (int): the number of Gaussian densities for each output dimension\n",
    "            hidden_sizes (list): a list of sizes for hidden layers\n",
    "            hidden_nonlinearity (nn.functional): nonlinearity for hidden layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_densities = num_densities\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.hidden_nonlinearity = hidden_nonlinearity\n",
    "        \n",
    "        # Create hidden layers\n",
    "        self.hidden_layers = MLP(input_dim=self.input_dim, \n",
    "                                 hidden_sizes=self.hidden_sizes, \n",
    "                                 hidden_nonlinearity=self.hidden_nonlinearity, \n",
    "                                 output_dim=None, \n",
    "                                 output_nonlinearity=None)\n",
    "        # Take out dimension of last hidden layer\n",
    "        in_features = self.hidden_sizes[-1]\n",
    "        # Create mixing coefficients head\n",
    "        self.pi_head = nn.Linear(in_features=in_features, out_features=self.num_densities)\n",
    "        # Create mean head\n",
    "        self.mu_head = nn.Linear(in_features=in_features, out_features=self.output_dim*self.num_densities)\n",
    "        # Create log-variance head\n",
    "        # Use log-variance allows to optimize values in [negative, 0, positive]\n",
    "        # To retrieve std, use exp(2*log-variance) rather than sqrt for better numerical stability\n",
    "        self.logvar_head = nn.Linear(in_features=in_features, out_features=self.output_dim*self.num_densities)\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self._init_params()\n",
    "        \n",
    "    def _init_params(self):\n",
    "        \"\"\"\n",
    "        Initialize the network parameters, weights, biases\n",
    "        \n",
    "        Orthogonal weight initialization and zero bias initialization\n",
    "        \"\"\"\n",
    "        # Initialization for mixing coefficients head\n",
    "        # Weight initialization\n",
    "        nn.init.orthogonal_(self.pi_head.weight, gain=1)  # gain=1 due to identity\n",
    "        # Bias initialization\n",
    "        nn.init.constant_(self.pi_head.bias, 0.0)\n",
    "        \n",
    "        # Initialization for mean head\n",
    "        # Weight initialization\n",
    "        nn.init.orthogonal_(self.mu_head.weight, gain=1)  # gain=1 due to identity\n",
    "        # Bias initialization\n",
    "        nn.init.constant_(self.mu_head.bias, 0.0)\n",
    "        \n",
    "        # Initialization for log-variance head\n",
    "        # Weight initialization\n",
    "        nn.init.orthogonal_(self.logvar_head.weight, gain=1)  # gain=1 due to identity\n",
    "        # Bias initialization\n",
    "        nn.init.constant_(self.logvar_head.bias, 0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Enforce the shape of x to be consistent with first layer\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        \n",
    "        # Forward pass till last hidden layer\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.hidden_nonlinearity(layer(x))\n",
    "            \n",
    "        # Forward pass through mixing coefficients head\n",
    "        pi = self.pi_head(x)\n",
    "        # Enforce each of coefficients are non-negative and summed up to 1, via softmax\n",
    "        pi = F.softmax(pi, dim=1)\n",
    "        \n",
    "        # Forward pass through mean head\n",
    "        mu = self.mu_head(x)\n",
    "        # Convert mean to tensor with shape [N, K, D]\n",
    "        mu = mu.view(-1, self.num_densities, self.output_dim)\n",
    "        \n",
    "        # Forward pass through log-variance head\n",
    "        logvar = self.logvar_head(x)\n",
    "        # Convert logvar to tensor with shape [N, K, D]\n",
    "        logvar = logvar.view(-1, self.num_densities, self.output_dim)\n",
    "        \n",
    "        return pi, mu, logvar\n",
    "    \n",
    "    def _calculate_batched_prob(self, mu, std, x):\n",
    "        \"\"\"\n",
    "        Calculate the probabilities for each data sampled by each density component. \n",
    "        Here the density is Gaussian. \n",
    "        \n",
    "        Args:\n",
    "            mu (Tensor): mean of Gaussian mixtures, shape [N, K, D]\n",
    "            std (Tensor): standard deviation of Gaussian mixtures, shape [N, K, D]\n",
    "            x (Tensor): input tensor, shape [N, D]\n",
    "            \n",
    "        Returns:\n",
    "            probs (Tensor): the calculated probabilities for each data and each density, shape [N, K]\n",
    "        \"\"\"\n",
    "        probs = []\n",
    "        \n",
    "        # Iterate over all density components\n",
    "        for i in range(self.num_densities):\n",
    "            # Retrieve means and stds\n",
    "            mu_i = mu[:, i, :]\n",
    "            std_i = std[:, i, :]\n",
    "            \n",
    "            # Create Gaussian distribution\n",
    "            dist = Normal(loc=mu_i, scale=std_i)\n",
    "            # Calculate the log-probability of x\n",
    "            logprobs = dist.log_prob(x)\n",
    "            # Calculate and record the probability for each training example\n",
    "            # For numerical stability: we sum up log-probabiilty before taking exp\n",
    "            # i.e. exp(log(prod(probs)) = exp(sum(log(probs)))\n",
    "            p = torch.exp(logprobs.sum(dim=1))\n",
    "            probs.append(p)\n",
    "            \n",
    "        # Stack probabilities with shape [N, K]\n",
    "        probs = torch.stack(probs, dim=1)\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def _MDN_loss(self, pi, mu, std, x):\n",
    "        \"\"\"\n",
    "        Calculate the loss function\n",
    "        \n",
    "        i.e. negative log-likelihood of the data given parameters from Gaussian mixtures\n",
    "        L = -\\sum_{n=1}^{N}(\\ln(\\sum_{k=1}^{K} pi_k*Gaussian probability))\n",
    "        \n",
    "        Args:\n",
    "            pi (Tensor): mixing coefficients, shape [N, K]\n",
    "            mu (Tensor): mean of Gaussian mixtures, shape [N, K, D]\n",
    "            std (Tensor): standard deviation of Gaussian mixtures, shape [N, K, D]\n",
    "            x (Tensor): input tensor, shape [N, D]\n",
    "\n",
    "        Returns:\n",
    "            loss (Tensor): calculated loss\n",
    "        \"\"\"\n",
    "        # Calculate Gaussian probabilities over batch for each mixture and each data dimension\n",
    "        gaussian_probs = self._calculate_batched_prob(mu=mu, \n",
    "                                                      std=std, \n",
    "                                                      x=x)\n",
    "        # Calculate the probability of Gaussian mixtures\n",
    "        p = pi*gaussian_probs\n",
    "        data_p = p.sum(dim=1)  # sum up for each data dimension\n",
    "        # Negative log-likelihood loss\n",
    "        loss = -torch.log(data_p)\n",
    "        # Average over the batch\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def sample(self, pi, mu, std):\n",
    "        \"\"\"\n",
    "        Sampling from Gaussian mixture. \n",
    "        \n",
    "        - Firstly sample categorically from mixing coefficients to determine a Gaussian distribution\n",
    "        - Then sample from selected Gaussian distribution\n",
    "        \n",
    "        Args:\n",
    "            pi (Tensor): mixing coefficients, shape [N, K]\n",
    "            mu (Tensor): mean of Gaussian mixtures, shape [N, K, D]\n",
    "            std (Tensor): standard deviation of Gaussian mixtures, shape [N, K, D]\n",
    "        \n",
    "        Returns:\n",
    "            x (Tensor): sampled data\n",
    "        \"\"\"\n",
    "        # Create a categorical distribution for mixing coefficients\n",
    "        pi_dist = Categorical(probs=pi)\n",
    "        # Sampling mixing coefficients to determine which Gaussian to sample from for each data\n",
    "        pi_samples = pi_dist.sample()\n",
    "        # Iteratively sample from selected Gaussian distributions\n",
    "        samples = []\n",
    "        for N_idx, pi_idx in enumerate(pi_samples):\n",
    "            # Create the selected Gaussian distribution\n",
    "            dist = Normal(loc=mu[N_idx, pi_idx, :], scale=std[N_idx, pi_idx, :])\n",
    "            # Sampling\n",
    "            samples.append(dist.sample())\n",
    "            \n",
    "        # Convert sampled data to a Tensor\n",
    "        samples = torch.stack(samples, dim=0)\n",
    "        \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 2])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = MDN(input_dim=2, \n",
    "            output_dim=2, \n",
    "            num_densities=3, \n",
    "            hidden_sizes=[6], \n",
    "            hidden_nonlinearity=F.tanh)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "from torch.distributions import Normal\n",
    "d1 = Normal(torch.tensor([0.5, 0.3]), torch.tensor([0.3, 0.1]))\n",
    "d2 = Normal(torch.tensor([1.5, -0.2]), torch.tensor([0.3, 0.66]))\n",
    "d3 = Normal(torch.tensor([-2.3, -1.2]), torch.tensor([0.5, 0.2]))\n",
    "a1 = torch.stack([d1.sample() for _ in range(100)], dim=0)\n",
    "a2 = torch.stack([d2.sample() for _ in range(100)], dim=0)\n",
    "a3 = torch.stack([d3.sample() for _ in range(100)], dim=0)\n",
    "data = torch.cat([a1, a2, a3], dim=0)\n",
    "data = data[torch.randperm(300)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
