{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Import lagom\n",
    "# Not useful once lagom is installed\n",
    "import sys\n",
    "sys.path.append('/home/zuo/Code/lagom/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use functiontools.partial to set make_env function without argument but internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'numpy' from '/home/zuo/anaconda3/envs/RL_server/lib/python3.6/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.swapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Process  # easier code than threading\n",
    "from multiprocessing import Pipe  # Much faster than Queue\n",
    "\n",
    "\n",
    "class CloudpickleWrapper(object):\n",
    "    \"\"\"\n",
    "    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n",
    "    \"\"\"\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.x()\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        import cloudpickle\n",
    "        return cloudpickle.dumps(self.x)\n",
    "    def __setstate__(self, ob):\n",
    "        import pickle\n",
    "        self.x = pickle.loads(ob)\n",
    "\n",
    "\n",
    "def worker(child_conn, parent_conn, make_env):\n",
    "    parent_conn.close()\n",
    "    # Create an environment\n",
    "    env = make_env()\n",
    "    \n",
    "    while True:\n",
    "        cmd, data = child_conn.recv()\n",
    "        if cmd == 'step':\n",
    "            obs, reward, done, info = env.step(data)\n",
    "            if done:\n",
    "                obs = env.reset()  # TODO: why reset\n",
    "            child_conn.send([obs, reward, done, info])\n",
    "        elif cmd == 'reset':\n",
    "            obs = env.reset()\n",
    "            child_conn.send(obs)\n",
    "        elif cmd == 'reset_task':\n",
    "            obs = env.reset_task()\n",
    "            child_conn.send(obs)\n",
    "        elif cmd == 'close':\n",
    "            child_conn.close()\n",
    "            break\n",
    "        elif cmd == 'get_spaces':\n",
    "            child_conn.send([env.observation_space, env.action_space])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "class SubprocVecEnv(VecEnv):\n",
    "    \"\"\"\n",
    "    Run a list of environment in subprocesses\n",
    "    \"\"\"\n",
    "    def __init__(self, list_make_env):\n",
    "        self.waiting = False\n",
    "        self.closed = False\n",
    "        self.num_envs = len(list_make_env)\n",
    "        self.parent_conns, self.child_conns = zip(*[Pipe() for _ in range(self.num_envs)])\n",
    "        self.processes = []\n",
    "        for parent_conn, child_conn, make_env in zip(self.parent_conns, self.child_conns, list_make_env):\n",
    "            self.processes.append(Process(target=worker, args=[child_conn, parent_conn, CloudpickleWrapper(make_env)]))  # TODO: CloudpickleWrapper make_env\n",
    "        for process in self.processes:\n",
    "            process.daemon = True  # if the main process crashes, we should not cause things to hang\n",
    "            process.start()\n",
    "        for conn in self.child_conns:\n",
    "            conn.close()\n",
    "        \n",
    "        # Obtain observation and action spaces\n",
    "        self.parent_conns[0].send(['get_spaces', None])\n",
    "        observation_space, action_space = self.parent_conns[0].recv()\n",
    "        super().__init__(self.num_envs, observation_space, action_space)\n",
    "        \n",
    "    def step_asyn(self, actions):\n",
    "        for parent_conn, action in zip(self.parent_conns, actions):\n",
    "            parent_conn.send(['step', action])\n",
    "            \n",
    "        self.waiting = True\n",
    "        \n",
    "    def step_wait(self):\n",
    "        observations, rewards, dones, infos = zip(*[parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "        self.waiting = False\n",
    "        return np.stack(observations), np.stack(rewards), np.stack(dones), infos\n",
    "    \n",
    "    def reset(self):\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['reset', None])\n",
    "        return np.stack([parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "    \n",
    "    def reset_task(self):\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['reset_task', None])\n",
    "        return np.stack([parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "    \n",
    "    def close(self):\n",
    "        if self.closed:\n",
    "            return\n",
    "        if self.waiting:\n",
    "            for parent_conn in self.parent_conns:\n",
    "                parent_conn.recv()\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['close', None])\n",
    "        for process in self.processes:\n",
    "            process.join()\n",
    "        self.closed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "T = 20\n",
    "L = 1000\n",
    "N = 100\n",
    "\n",
    "x = np.empty((N, L), 'int64')\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "data = np.sin(x/T).astype('float32')\n",
    "\n",
    "\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 51)\n",
    "        self.linear = nn.Linear(51, 1)\n",
    "        \n",
    "    def forward(self, x, future=0):\n",
    "        outputs = []\n",
    "        batch_size, x_size = x.size()\n",
    "        \n",
    "        h_t = torch.zeros(batch_size, 51)\n",
    "        c_t = torch.zeros(batch_size, 51)\n",
    "        h_t_2 = torch.zeros(batch_size, 51)\n",
    "        c_t_2 = torch.zeros(batch_size, 51)\n",
    "        \n",
    "        chunks = x.chunk(x_size, dim=1)\n",
    "        \n",
    "        for x_t in chunks:\n",
    "            h_t, c_t = self.lstm1(x_t, (h_t, c_t))\n",
    "            h_t_2, c_t_2 = self.lstm2(h_t, (h_t_2, c_t_2))\n",
    "            \n",
    "            output = self.linear(h_t_2)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        for _ in range(future):  # if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t_2, c_t_2 = self.lstm2(h_t, (h_t_2, c_t_2))\n",
    "            \n",
    "            output = self.linear(h_t_2)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1).squeeze(2)\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input = torch.from_numpy(data[3:, :-1])\n",
    "    target = torch.from_numpy(data[3:, 1:])\n",
    "    test_input = torch.from_numpy(data[:3, :-1])\n",
    "    test_target = torch.from_numpy(data[:3, 1:])\n",
    "\n",
    "    seq = Sequence()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Use LBFGS since we load whole data to train\n",
    "    optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n",
    "\n",
    "    for i in range(2):\n",
    "        print(f'STEP: {i}')\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            out = seq(input)\n",
    "            loss = criterion(out, target)\n",
    "            print(f'Loss: {loss.item()}')\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # Prediction\n",
    "        future = 1000\n",
    "        pred = seq(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-future], test_target)\n",
    "        print(f'Test loss: {loss.item()}')\n",
    "        y = pred.data.numpy()\n",
    "\n",
    "        # Drawing\n",
    "        plt.figure(figsize=(30, 10))\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        def draw(yi, color):\n",
    "            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth=2.0)\n",
    "            plt.plot(np.arange(input.size(1), input.size(1)+future), yi[input.size(1):], color + ':', linewidth=2.0)\n",
    "        draw(y[0], 'r')\n",
    "        draw(y[1], 'g')\n",
    "        draw(y[2], 'b')\n",
    "        \n",
    "        plt.savefig(f'logs/{i}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Import lagom\n",
    "# Not useful once lagom is installed\n",
    "import sys\n",
    "sys.path.append('/home/zuo/Code/lagom/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lagom.core.networks import MLP\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoders (VAE) with MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 encoder_sizes, \n",
    "                 encoder_nonlinearity, \n",
    "                 latent_dim, \n",
    "                 decoder_sizes, \n",
    "                 decoder_nonlinearity):\n",
    "        \"\"\"\n",
    "        Set up VAE with configurations\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): input dimension\n",
    "            encoder_sizes (list): a list of sizes for encoder hidden layers\n",
    "            encoder_nonlinearity (nn.functional): nonlinearity for encoder hidden layers\n",
    "            latent_dim (int): latent dimension\n",
    "            decoder_sizes (list): a list of sizes for decoder hidden layers\n",
    "            decoder_nonlinearity (nn.functional): nonlinearity for decoder hidden layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_sizes = encoder_sizes\n",
    "        self.encoder_nonlinearity = encoder_nonlinearity\n",
    "        self.latent_dim = latent_dim\n",
    "        self.decoder_sizes = decoder_sizes\n",
    "        self.decoder_nonlinearity = decoder_nonlinearity\n",
    "        \n",
    "        # Create encoder network\n",
    "        self.encoder = MLP(input_dim=self.input_dim, \n",
    "                           hidden_sizes=self.encoder_sizes, \n",
    "                           hidden_nonlinearity=self.encoder_nonlinearity, \n",
    "                           output_dim=None, \n",
    "                           output_nonlinearity=None)\n",
    "        # Last layer of encoder network to output mean and log-variance for latent variable\n",
    "        self.mu_head = nn.Linear(in_features=self.encoder_sizes[-1], out_features=self.latent_dim)\n",
    "        self.logvar_head = nn.Linear(in_features=self.encoder_sizes[-1], out_features=self.latent_dim)\n",
    "        \n",
    "        # Create decoder network\n",
    "        self.decoder = MLP(input_dim=self.latent_dim, \n",
    "                           hidden_sizes=self.decoder_sizes, \n",
    "                           hidden_nonlinearity=self.decoder_nonlinearity, \n",
    "                           output_dim=self.input_dim, \n",
    "                           output_nonlinearity=None)\n",
    "        \n",
    "        # Initialize parameters for newly defined layers\n",
    "        self._init_params()\n",
    "        \n",
    "    def _init_params(self):\n",
    "        \"\"\"\n",
    "        Initialize the network parameters, weights, biases\n",
    "        \n",
    "        Orthogonal weight initialization and zero bias initialization\n",
    "        \"\"\"\n",
    "        # Initialize mu_head, it does not have nonlinearity\n",
    "        # Weight initialization\n",
    "        nn.init.orthogonal_(self.mu_head.weight, gain=1)  # gain=1 due to identity\n",
    "        # Bias initialization\n",
    "        nn.init.constant_(self.mu_head.bias, 0.0)\n",
    "        \n",
    "        # Initialize logvar_head, it does not have nonlinearity\n",
    "        # Weight initialization\n",
    "        nn.init.orthogonal_(self.logvar_head.weight, gain=1)  # gain=1 due to identity\n",
    "        # Bias initialization\n",
    "        nn.init.constant_(self.logvar_head.bias, 0.0)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of encoder network. \n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): input tensor to the encoder network\n",
    "            \n",
    "        Returns:\n",
    "            mu (Tensor): mean of the latent variable\n",
    "            logvar (Tensor): log-variance of the latent variable. \n",
    "                Note that log operation allows to optimize negative values,\n",
    "                though variance must be non-negative. \n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu_head(x)\n",
    "        logvar = self.logvar_head(x)\n",
    "        \n",
    "        return mu, logvar\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass of decoder network\n",
    "        \n",
    "        Args:\n",
    "            z (Tensor): the sampled latent variable\n",
    "            \n",
    "        Returns:\n",
    "            x (Tensor): the reconstruction of the input\n",
    "        \"\"\"\n",
    "        x = self.decoder(z)\n",
    "        # Use sigmoid to constraint all values in (0, 1)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Sampling using reparameterization trick\n",
    "        \n",
    "        i.e. mu + eps*std, eps sampled from N(0, 1)\n",
    "        \n",
    "        Args:\n",
    "            mu (Tensor): mean of a Gaussian random variable\n",
    "            logvar (Tensor): log-variance of a Gaussian random variable\n",
    "                Note that log operation allows to optimize negative values,\n",
    "                though variance must be non-negative.\n",
    "        \n",
    "        Returns:\n",
    "            sampled tensor according to the reparameterization trick\n",
    "        \"\"\"\n",
    "        if self.training:  # training: sample with reparameterization trick\n",
    "            # Recover std from log-variance\n",
    "            # 0.5*logvar by logarithm law is more numerically stable than taking square root\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            # Sample standard Gaussian noise\n",
    "            eps = torch.randn_like(std)\n",
    "            \n",
    "            return mu + eps*std\n",
    "        else:  # evaluation: no sampling, simply pass mu\n",
    "            return mu\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Enforce the shape of x to be consistent with first layer\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        \n",
    "        # Forward pass through encoder to get mu and logvar for latent variable\n",
    "        mu, logvar = self.encode(x)\n",
    "        # Sample latent variable by reparameterization trick\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        # Forward pass through decoder of sampled latent variable to reconstruct input\n",
    "        reconstructed_x = self.decode(z)\n",
    "        \n",
    "        return reconstructed_x, mu, logvar\n",
    "    \n",
    "    def calculate_loss(self, reconstructed_x, x, mu, logvar):\n",
    "        \"\"\"\n",
    "        Calculate the VAE loss function\n",
    "        VAE_loss = Reconstruction_loss + KL_loss\n",
    "        Note that the losses are summed over all elements and batch\n",
    "        \n",
    "        For details, see https://arxiv.org/abs/1312.6114\n",
    "        The KL loss is derived in Appendix B\n",
    "        \n",
    "        Args:\n",
    "            reconstructed_x (Tensor): reconstructed x output from decoder\n",
    "            x (Tensor): ground-truth x\n",
    "            mu (Tensor): mean of the latent variable\n",
    "            logvar (Tensor): log-variance of the latent variable\n",
    "        \n",
    "        Returns:\n",
    "            loss (Tensor): VAE loss\n",
    "        \"\"\"\n",
    "        # Enforce the shape of x is the same as reconstructed x\n",
    "        x = x.view_as(reconstructed_x)\n",
    "        \n",
    "        # Calculate reconstruction loss\n",
    "        reconstruction_loss = F.binary_cross_entropy(reconstructed_x, \n",
    "                                                     x, \n",
    "                                                     size_average=False)  # summed up losses\n",
    "        # Calculate KL loss\n",
    "        # Gaussian: 0.5*sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        KL_loss = -0.5*torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "        \n",
    "        loss = reconstruction_loss + KL_loss\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 546.562805\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 342.671112\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 240.605652\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 223.882416\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 214.755920\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 210.523834\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 206.643921\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 201.060501\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 193.725327\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 195.931458\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 181.105438\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 176.844101\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 174.347122\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 175.428955\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 163.916931\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 163.429047\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 160.158066\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 154.313385\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 158.951767\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 154.396652\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 147.281815\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 145.872711\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 148.308594\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 140.088028\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 148.573456\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 142.697189\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 146.435303\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 141.415344\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 147.917557\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 138.010056\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 145.600845\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 137.058990\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 142.635712\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 135.695587\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 141.237411\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 132.162491\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 129.904144\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 135.286362\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 133.029190\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 128.378891\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 127.306175\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 131.056320\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 131.926208\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 128.843857\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 131.946899\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 128.254059\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 133.601761\n",
      "====> Epoch: 1 Average loss: 165.3256\n",
      "====> Test set loss: 119.1399\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "config = {}\n",
    "config['batch_size'] = 128\n",
    "config['epochs'] = 1\n",
    "config['seed'] = 1\n",
    "config['log_interval'] = 10\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(config['seed'])\n",
    "\n",
    "# Automatic check if there is GPU\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if cuda else 'cpu')\n",
    "\n",
    "# Define GPU-dependent keywords for DataLoader\n",
    "if cuda:\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "else:\n",
    "    kwargs = {}\n",
    "train_loader = DataLoader(datasets.MNIST('data/', \n",
    "                                         train=True, \n",
    "                                         download=True, \n",
    "                                         transform=transforms.ToTensor()), \n",
    "                          batch_size=config['batch_size'], \n",
    "                          shuffle=True, \n",
    "                          **kwargs)\n",
    "test_loader = DataLoader(datasets.MNIST('data/', \n",
    "                                         train=False, \n",
    "                                         transform=transforms.ToTensor()), \n",
    "                         batch_size=config['batch_size'], \n",
    "                         shuffle=True, \n",
    "                         **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "model = VAE(input_dim=784, \n",
    "            encoder_sizes=[400], \n",
    "            encoder_nonlinearity=F.relu, \n",
    "            latent_dim=20, \n",
    "            decoder_sizes=[400], \n",
    "            decoder_nonlinearity=F.relu)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = model.calculate_loss(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % config['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += model.calculate_loss(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(config['batch_size'], 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'data/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "for epoch in range(1, config['epochs'] + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, 20).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                   'data/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "====> Epoch: 1 Average loss: 164.4686\n",
    "====> Test set loss: 119.2985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "165.3256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
