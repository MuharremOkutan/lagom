{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "# ID: 0\n",
      "# seed: 0\n",
      "# hidden_sizes: [16]\n",
      "# hidden_nonlinearity: <function relu at 0x7ff613f1c6a8>\n",
      "# lr: 0.01\n",
      "# gamma: 0.99\n",
      "# T: 30\n",
      "# use_optimal_T: True\n",
      "# predict_value: False\n",
      "# standardize_r: True\n",
      "# goal_sampler: <class 'goal_sampler.sw_ucb_g.SWUCBgGoalSampler'>\n",
      "# num_goal: 4\n",
      "# train_iter: 2\n",
      "# eval_iter: 1\n",
      "# train_num_epi: 30\n",
      "# eval_num_epi: 100\n",
      "# log_interval: 1\n",
      "##################################################\n",
      "\n",
      "Sampled Goal (1/4): [6, 2]\n",
      "A* optimal steps: 1\n",
      "('Train Iteration', 1):\n",
      "\tTotal loss: 0.24578095972537994\n",
      "\tNum Episodes: 30\n",
      "\tAverage Return: 0.3333333333333333\n",
      "\tAverage Discounted Return: 0.3333333333333333\n",
      "\tStd Return: 0.4714045207910317\n",
      "\tMin Return: 0\n",
      "\tMax Return: 1\n",
      "('Train Iteration', 2):\n",
      "\tTotal loss: 0.36471688747406006\n",
      "\tNum Episodes: 30\n",
      "\tAverage Return: 0.6333333333333333\n",
      "\tAverage Discounted Return: 0.6333333333333333\n",
      "\tStd Return: 0.4818944098266986\n",
      "\tMin Return: 0\n",
      "\tMax Return: 1\n",
      "########### 0.4666666666666667, 0.8\n",
      "A* optimal steps: 11\n",
      "A* optimal steps: 10\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 10\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 7\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 6\n",
      "A* optimal steps: 7\n",
      "A* optimal steps: 5\n",
      "A* optimal steps: 6\n",
      "A* optimal steps: 1\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 3\n",
      "A* optimal steps: 4\n",
      "A* optimal steps: 5\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 1\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 3\n",
      "A* optimal steps: 4\n",
      "# Evaluation: \n",
      "\tMean success rate over goal space: 0.09833333333333334\n",
      "\tAll success rate over goal space: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.14, 0.21, 0.18, 0.09, 0.05, 0.28, 0.58, 0.44, 0.26, 0.11]\n",
      "OrderedDict([(('Group', 0), OrderedDict([(('Goal', (5, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 3)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 2)), {'N': 1, 'Q': deque([0.33333333333333337], maxlen=200)}), (('Goal', (6, 3)), {'N': 0, 'Q': deque([], maxlen=200)})])), (('Group', 1), OrderedDict([(('Goal', (1, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (3, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (3, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (4, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (4, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 5)), {'N': 0, 'Q': deque([], maxlen=200)})])), (('Group', 2), OrderedDict([(('Goal', (1, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 3)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 3)), {'N': 0, 'Q': deque([], maxlen=200)})]))])\n",
      "\n",
      "Sampled Goal (2/4): [3, 5]\n",
      "A* optimal steps: 7\n",
      "('Train Iteration', 1):\n",
      "\tTotal loss: 0.011683437041938305\n",
      "\tNum Episodes: 30\n",
      "\tAverage Return: 0.03333333333333333\n",
      "\tAverage Discounted Return: 0.03138267164669999\n",
      "\tStd Return: 0.1795054935711501\n",
      "\tMin Return: 0\n",
      "\tMax Return: 1\n",
      "('Train Iteration', 2):\n",
      "\tTotal loss: 0.0\n",
      "\tNum Episodes: 30\n",
      "\tAverage Return: 0.0\n",
      "\tAverage Discounted Return: 0.0\n",
      "\tStd Return: 0.0\n",
      "\tMin Return: 0\n",
      "\tMax Return: 0\n",
      "########### 0.0, 0.0\n",
      "A* optimal steps: 11\n",
      "A* optimal steps: 10\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 10\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 7\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 6\n",
      "A* optimal steps: 7\n",
      "A* optimal steps: 5\n",
      "A* optimal steps: 6\n",
      "A* optimal steps: 1\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 3\n",
      "A* optimal steps: 4\n",
      "A* optimal steps: 5\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 1\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 3\n",
      "A* optimal steps: 4\n",
      "# Evaluation: \n",
      "\tMean success rate over goal space: 0.13125\n",
      "\tAll success rate over goal space: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.03, 0.16, 0.19, 0.15, 0.11, 0.13, 0.16, 0.8, 0.62, 0.41, 0.35]\n",
      "OrderedDict([(('Group', 0), OrderedDict([(('Goal', (5, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 3)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 2)), {'N': 1, 'Q': deque([0.33333333333333337], maxlen=200)}), (('Goal', (6, 3)), {'N': 0, 'Q': deque([], maxlen=200)})])), (('Group', 1), OrderedDict([(('Goal', (1, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (3, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (3, 5)), {'N': 1, 'Q': deque([0.0], maxlen=200)}), (('Goal', (4, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (4, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 5)), {'N': 0, 'Q': deque([], maxlen=200)})])), (('Group', 2), OrderedDict([(('Goal', (1, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 3)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 3)), {'N': 0, 'Q': deque([], maxlen=200)})]))])\n",
      "\n",
      "Sampled Goal (3/4): [1, 1]\n",
      "A* optimal steps: 11\n",
      "('Train Iteration', 1):\n",
      "\tTotal loss: 0.0\n",
      "\tNum Episodes: 30\n",
      "\tAverage Return: 0.0\n",
      "\tAverage Discounted Return: 0.0\n",
      "\tStd Return: 0.0\n",
      "\tMin Return: 0\n",
      "\tMax Return: 0\n",
      "('Train Iteration', 2):\n",
      "\tTotal loss: 0.0\n",
      "\tNum Episodes: 30\n",
      "\tAverage Return: 0.0\n",
      "\tAverage Discounted Return: 0.0\n",
      "\tStd Return: 0.0\n",
      "\tMin Return: 0\n",
      "\tMax Return: 0\n",
      "########### 0.0, 0.0\n",
      "A* optimal steps: 11\n",
      "A* optimal steps: 10\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 10\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 7\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 6\n",
      "A* optimal steps: 7\n",
      "A* optimal steps: 5\n",
      "A* optimal steps: 6\n",
      "A* optimal steps: 1\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 3\n",
      "A* optimal steps: 4\n",
      "A* optimal steps: 5\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 1\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 3\n",
      "A* optimal steps: 4\n",
      "# Evaluation: \n",
      "\tMean success rate over goal space: 0.15\n",
      "\tAll success rate over goal space: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.01, 0.04, 0.1, 0.13, 0.23, 0.2, 0.18, 0.14, 0.83, 0.64, 0.62, 0.47]\n",
      "OrderedDict([(('Group', 0), OrderedDict([(('Goal', (5, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 3)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 2)), {'N': 1, 'Q': deque([0.33333333333333337], maxlen=200)}), (('Goal', (6, 3)), {'N': 0, 'Q': deque([], maxlen=200)})])), (('Group', 1), OrderedDict([(('Goal', (1, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (3, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (3, 5)), {'N': 1, 'Q': deque([0.0], maxlen=200)}), (('Goal', (4, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (4, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 5)), {'N': 0, 'Q': deque([], maxlen=200)})])), (('Group', 2), OrderedDict([(('Goal', (1, 1)), {'N': 1, 'Q': deque([0.0], maxlen=200)}), (('Goal', (1, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 3)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 3)), {'N': 0, 'Q': deque([], maxlen=200)})]))])\n",
      "\n",
      "Sampled Goal (4/4): [5, 1]\n",
      "A* optimal steps: 1\n",
      "('Train Iteration', 1):\n",
      "\tTotal loss: 0.49188947677612305\n",
      "\tNum Episodes: 30\n",
      "\tAverage Return: 0.23333333333333334\n",
      "\tAverage Discounted Return: 0.23333333333333334\n",
      "\tStd Return: 0.4229525846816506\n",
      "\tMin Return: 0\n",
      "\tMax Return: 1\n",
      "('Train Iteration', 2):\n",
      "\tTotal loss: 0.3433915376663208\n",
      "\tNum Episodes: 30\n",
      "\tAverage Return: 0.16666666666666666\n",
      "\tAverage Discounted Return: 0.16666666666666666\n",
      "\tStd Return: 0.37267799624996495\n",
      "\tMin Return: 0\n",
      "\tMax Return: 1\n",
      "########### 0.0, 0.0\n",
      "A* optimal steps: 11\n",
      "A* optimal steps: 10\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 10\n",
      "A* optimal steps: 9\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 7\n",
      "A* optimal steps: 8\n",
      "A* optimal steps: 6\n",
      "A* optimal steps: 7\n",
      "A* optimal steps: 5\n",
      "A* optimal steps: 6\n",
      "A* optimal steps: 1\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 3\n",
      "A* optimal steps: 4\n",
      "A* optimal steps: 5\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 1\n",
      "A* optimal steps: 2\n",
      "A* optimal steps: 3\n",
      "A* optimal steps: 4\n",
      "# Evaluation: \n",
      "\tMean success rate over goal space: 0.16333333333333333\n",
      "\tAll success rate over goal space: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03, 0.05, 0.18, 0.24, 0.23, 0.24, 0.22, 0.02, 0.86, 0.7, 0.59, 0.56]\n",
      "OrderedDict([(('Group', 0), OrderedDict([(('Goal', (5, 1)), {'N': 1, 'Q': deque([0.0], maxlen=200)}), (('Goal', (5, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 3)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 2)), {'N': 1, 'Q': deque([0.33333333333333337], maxlen=200)}), (('Goal', (6, 3)), {'N': 0, 'Q': deque([], maxlen=200)})])), (('Group', 1), OrderedDict([(('Goal', (1, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (3, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (3, 5)), {'N': 1, 'Q': deque([0.0], maxlen=200)}), (('Goal', (4, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (4, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (5, 5)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 4)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (6, 5)), {'N': 0, 'Q': deque([], maxlen=200)})])), (('Group', 2), OrderedDict([(('Goal', (1, 1)), {'N': 1, 'Q': deque([0.0], maxlen=200)}), (('Goal', (1, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (1, 3)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 1)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 2)), {'N': 0, 'Q': deque([], maxlen=200)}), (('Goal', (2, 3)), {'N': 0, 'Q': deque([], maxlen=200)})]))])\n",
      "\n",
      "Total time: 72.54 s\n"
     ]
    }
   ],
   "source": [
    "# TEMP: Import lagom\n",
    "# Not useful once lagom is installed\n",
    "import sys\n",
    "sys.path.append('/home/zuo/Documents/lagom/')\n",
    "\n",
    "from time import time\n",
    "\n",
    "from experiment import Experiment\n",
    "from algo import GoalSelection\n",
    "from lagom.core.utils import Logger\n",
    "\n",
    "logger = Logger(name='goal_selection')\n",
    "algo = GoalSelection(name='goal_selection')\n",
    "experiment = Experiment(logger)\n",
    "\n",
    "experiment.add_algo(algo)\n",
    "\n",
    "start_time = time()\n",
    "experiment.benchmark(num_process=1)\n",
    "print(f'\\nTotal time: {time() - start_time:.2f} s')\n",
    "\n",
    "# Save loggings\n",
    "logger.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('goal_selection',\n",
       "              {('ID',\n",
       "                0): OrderedDict([(('Sampled goal', 0, (6, 2)),\n",
       "                             OrderedDict([(('Train Iteration', 1),\n",
       "                                           OrderedDict([('Total loss',\n",
       "                                                         0.24578095972537994),\n",
       "                                                        ('Num Episodes', 30),\n",
       "                                                        ('Average Return',\n",
       "                                                         0.3333333333333333),\n",
       "                                                        ('Average Discounted Return',\n",
       "                                                         0.3333333333333333),\n",
       "                                                        ('Std Return',\n",
       "                                                         0.4714045207910317),\n",
       "                                                        ('Min Return', 0),\n",
       "                                                        ('Max Return', 1)])),\n",
       "                                          (('Train Iteration', 2),\n",
       "                                           OrderedDict([('Total loss',\n",
       "                                                         0.36471688747406006),\n",
       "                                                        ('Num Episodes', 30),\n",
       "                                                        ('Average Return',\n",
       "                                                         0.6333333333333333),\n",
       "                                                        ('Average Discounted Return',\n",
       "                                                         0.6333333333333333),\n",
       "                                                        ('Std Return',\n",
       "                                                         0.4818944098266986),\n",
       "                                                        ('Min Return', 0),\n",
       "                                                        ('Max Return', 1)])),\n",
       "                                          ('Eval',\n",
       "                                           OrderedDict([('All success rate',\n",
       "                                                         [[(1, 1), 0.0],\n",
       "                                                          [(1, 2), 0.0],\n",
       "                                                          [(1, 3), 0.0],\n",
       "                                                          [(1, 4), 0.0],\n",
       "                                                          [(1, 5), 0.0],\n",
       "                                                          [(2, 1), 0.0],\n",
       "                                                          [(2, 2), 0.0],\n",
       "                                                          [(2, 3), 0.0],\n",
       "                                                          [(2, 4), 0.0],\n",
       "                                                          [(2, 5), 0.0],\n",
       "                                                          [(3, 4), 0.0],\n",
       "                                                          [(3, 5), 0.0],\n",
       "                                                          [(4, 4), 0.01],\n",
       "                                                          [(4, 5), 0.01],\n",
       "                                                          [(5, 1), 0.14],\n",
       "                                                          [(5, 2), 0.21],\n",
       "                                                          [(5, 3), 0.18],\n",
       "                                                          [(5, 4), 0.09],\n",
       "                                                          [(5, 5), 0.05],\n",
       "                                                          [(6, 1), 0.28],\n",
       "                                                          [(6, 2), 0.58],\n",
       "                                                          [(6, 3), 0.44],\n",
       "                                                          [(6, 4), 0.26],\n",
       "                                                          [(6, 5), 0.11]]),\n",
       "                                                        ('Mean success rate',\n",
       "                                                         0.09833333333333334)]))])),\n",
       "                            (('Sampled goal', 1, (3, 5)),\n",
       "                             OrderedDict([(('Train Iteration', 1),\n",
       "                                           OrderedDict([('Total loss',\n",
       "                                                         0.011683437041938305),\n",
       "                                                        ('Num Episodes', 30),\n",
       "                                                        ('Average Return',\n",
       "                                                         0.03333333333333333),\n",
       "                                                        ('Average Discounted Return',\n",
       "                                                         0.03138267164669999),\n",
       "                                                        ('Std Return',\n",
       "                                                         0.1795054935711501),\n",
       "                                                        ('Min Return', 0),\n",
       "                                                        ('Max Return', 1)])),\n",
       "                                          (('Train Iteration', 2),\n",
       "                                           OrderedDict([('Total loss', 0.0),\n",
       "                                                        ('Num Episodes', 30),\n",
       "                                                        ('Average Return',\n",
       "                                                         0.0),\n",
       "                                                        ('Average Discounted Return',\n",
       "                                                         0.0),\n",
       "                                                        ('Std Return', 0.0),\n",
       "                                                        ('Min Return', 0),\n",
       "                                                        ('Max Return', 0)])),\n",
       "                                          ('Eval',\n",
       "                                           OrderedDict([('All success rate',\n",
       "                                                         [[(1, 1), 0.0],\n",
       "                                                          [(1, 2), 0.0],\n",
       "                                                          [(1, 3), 0.0],\n",
       "                                                          [(1, 4), 0.0],\n",
       "                                                          [(1, 5), 0.0],\n",
       "                                                          [(2, 1), 0.0],\n",
       "                                                          [(2, 2), 0.0],\n",
       "                                                          [(2, 3), 0.0],\n",
       "                                                          [(2, 4), 0.0],\n",
       "                                                          [(2, 5), 0.0],\n",
       "                                                          [(3, 4), 0.0],\n",
       "                                                          [(3, 5), 0.0],\n",
       "                                                          [(4, 4), 0.04],\n",
       "                                                          [(4, 5), 0.03],\n",
       "                                                          [(5, 1), 0.16],\n",
       "                                                          [(5, 2), 0.19],\n",
       "                                                          [(5, 3), 0.15],\n",
       "                                                          [(5, 4), 0.11],\n",
       "                                                          [(5, 5), 0.13],\n",
       "                                                          [(6, 1), 0.16],\n",
       "                                                          [(6, 2), 0.8],\n",
       "                                                          [(6, 3), 0.62],\n",
       "                                                          [(6, 4), 0.41],\n",
       "                                                          [(6, 5), 0.35]]),\n",
       "                                                        ('Mean success rate',\n",
       "                                                         0.13125)]))])),\n",
       "                            (('Sampled goal', 2, (1, 1)),\n",
       "                             OrderedDict([(('Train Iteration', 1),\n",
       "                                           OrderedDict([('Total loss', 0.0),\n",
       "                                                        ('Num Episodes', 30),\n",
       "                                                        ('Average Return',\n",
       "                                                         0.0),\n",
       "                                                        ('Average Discounted Return',\n",
       "                                                         0.0),\n",
       "                                                        ('Std Return', 0.0),\n",
       "                                                        ('Min Return', 0),\n",
       "                                                        ('Max Return', 0)])),\n",
       "                                          (('Train Iteration', 2),\n",
       "                                           OrderedDict([('Total loss', 0.0),\n",
       "                                                        ('Num Episodes', 30),\n",
       "                                                        ('Average Return',\n",
       "                                                         0.0),\n",
       "                                                        ('Average Discounted Return',\n",
       "                                                         0.0),\n",
       "                                                        ('Std Return', 0.0),\n",
       "                                                        ('Min Return', 0),\n",
       "                                                        ('Max Return', 0)])),\n",
       "                                          ('Eval',\n",
       "                                           OrderedDict([('All success rate',\n",
       "                                                         [[(1, 1), 0.0],\n",
       "                                                          [(1, 2), 0.0],\n",
       "                                                          [(1, 3), 0.0],\n",
       "                                                          [(1, 4), 0.0],\n",
       "                                                          [(1, 5), 0.0],\n",
       "                                                          [(2, 1), 0.0],\n",
       "                                                          [(2, 2), 0.0],\n",
       "                                                          [(2, 3), 0.0],\n",
       "                                                          [(2, 4), 0.01],\n",
       "                                                          [(2, 5), 0.0],\n",
       "                                                          [(3, 4), 0.0],\n",
       "                                                          [(3, 5), 0.0],\n",
       "                                                          [(4, 4), 0.01],\n",
       "                                                          [(4, 5), 0.04],\n",
       "                                                          [(5, 1), 0.1],\n",
       "                                                          [(5, 2), 0.13],\n",
       "                                                          [(5, 3), 0.23],\n",
       "                                                          [(5, 4), 0.2],\n",
       "                                                          [(5, 5), 0.18],\n",
       "                                                          [(6, 1), 0.14],\n",
       "                                                          [(6, 2), 0.83],\n",
       "                                                          [(6, 3), 0.64],\n",
       "                                                          [(6, 4), 0.62],\n",
       "                                                          [(6, 5), 0.47]]),\n",
       "                                                        ('Mean success rate',\n",
       "                                                         0.15)]))])),\n",
       "                            (('Sampled goal', 3, (5, 1)),\n",
       "                             OrderedDict([(('Train Iteration', 1),\n",
       "                                           OrderedDict([('Total loss',\n",
       "                                                         0.49188947677612305),\n",
       "                                                        ('Num Episodes', 30),\n",
       "                                                        ('Average Return',\n",
       "                                                         0.23333333333333334),\n",
       "                                                        ('Average Discounted Return',\n",
       "                                                         0.23333333333333334),\n",
       "                                                        ('Std Return',\n",
       "                                                         0.4229525846816506),\n",
       "                                                        ('Min Return', 0),\n",
       "                                                        ('Max Return', 1)])),\n",
       "                                          (('Train Iteration', 2),\n",
       "                                           OrderedDict([('Total loss',\n",
       "                                                         0.3433915376663208),\n",
       "                                                        ('Num Episodes', 30),\n",
       "                                                        ('Average Return',\n",
       "                                                         0.16666666666666666),\n",
       "                                                        ('Average Discounted Return',\n",
       "                                                         0.16666666666666666),\n",
       "                                                        ('Std Return',\n",
       "                                                         0.37267799624996495),\n",
       "                                                        ('Min Return', 0),\n",
       "                                                        ('Max Return', 1)])),\n",
       "                                          ('Eval',\n",
       "                                           OrderedDict([('All success rate',\n",
       "                                                         [[(1, 1), 0.0],\n",
       "                                                          [(1, 2), 0.0],\n",
       "                                                          [(1, 3), 0.0],\n",
       "                                                          [(1, 4), 0.0],\n",
       "                                                          [(1, 5), 0.0],\n",
       "                                                          [(2, 1), 0.0],\n",
       "                                                          [(2, 2), 0.0],\n",
       "                                                          [(2, 3), 0.0],\n",
       "                                                          [(2, 4), 0.0],\n",
       "                                                          [(2, 5), 0.0],\n",
       "                                                          [(3, 4), 0.0],\n",
       "                                                          [(3, 5), 0.0],\n",
       "                                                          [(4, 4), 0.03],\n",
       "                                                          [(4, 5), 0.05],\n",
       "                                                          [(5, 1), 0.18],\n",
       "                                                          [(5, 2), 0.24],\n",
       "                                                          [(5, 3), 0.23],\n",
       "                                                          [(5, 4), 0.24],\n",
       "                                                          [(5, 5), 0.22],\n",
       "                                                          [(6, 1), 0.02],\n",
       "                                                          [(6, 2), 0.86],\n",
       "                                                          [(6, 3), 0.7],\n",
       "                                                          [(6, 4), 0.59],\n",
       "                                                          [(6, 5), 0.56]]),\n",
       "                                                        ('Mean success rate',\n",
       "                                                         0.16333333333333333)]))]))])})])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.env.get_source_env().maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "a = deque([], maxlen=4)\n",
    "a.append(1)\n",
    "a.append(2)\n",
    "a.append(3)\n",
    "a.append(4)\n",
    "#a.append(5)\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2]\n",
      "[2, 5]\n",
      "[1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = SWUCBgGoalSampler(None, None)\n",
    "[print(g.sample()) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = deque([], maxlen=3)\n",
    "[a.append(i) for i in range(3)]\n",
    "a.append(3)\n",
    "len(a) == a.maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "from collections import OrderedDict\n",
    "\n",
    "from .base import BaseGoalSampler\n",
    "from ..utils import get_optimal_steps\n",
    "\n",
    "from lagom.runner import Runner\n",
    "\n",
    "\n",
    "class SWUCBgGoalSampler(BaseGoalSampler):\n",
    "    def __init__(self, runner, config):\n",
    "        super().__init__(runner, config)\n",
    "        \n",
    "        # Counter for iterations\n",
    "        self.t = 0\n",
    "        \n",
    "        # Sliding window\n",
    "        self.h = 5\n",
    "        \n",
    "        # Partition of the goal space into groups\n",
    "        self.groups = self._partition_goal_space()\n",
    "        self.num_groups = len(self.groups)\n",
    "        \n",
    "        # Sliding-window queue of selected information\n",
    "        self.queue = deque([], maxlen=self.h)  # queue with size as sliding window\n",
    "        \n",
    "        # Initialize goal value estimate\n",
    "        self.infos = OrderedDict()\n",
    "        for i, group in enumerate(self.groups):  # iterate over groups of goals\n",
    "            d = OrderedDict()\n",
    "            for goal in group:  # iterate over goals\n",
    "                d[('Goal', tuple(goal))] = {'N': 0, 'Q': deque([], maxlen=self.h)}\n",
    "            # Add to dictionary\n",
    "            self.infos[('Group', i)] = d\n",
    "            \n",
    "        # hyperparams from SWUCB-g paper\n",
    "        self.D1 = 0.1\n",
    "        self.D2 = 2\n",
    "        self.gamma1 = 2\n",
    "        self.gamma2 = 0.5\n",
    "        self.alphas = [len(group)+5 for group in self.groups]\n",
    "            \n",
    "    def _partition_goal_space(self):\n",
    "        area1 = [[5, 1], [5, 2], [5, 3],\n",
    "                 [6, 1], [6, 2], [6, 3]]\n",
    "        area2 = [[1, 4], [1, 5], \n",
    "                 [2, 4], [2, 5], \n",
    "                 [3, 4], [3, 5],\n",
    "                 [4, 4], [4, 5],\n",
    "                 [5, 4], [5, 5],\n",
    "                 [6, 4], [6, 5]]\n",
    "        area3 = [[1, 1], [1, 2], [1, 3], \n",
    "                 [2, 1], [2, 2], [2, 3]]\n",
    "        \n",
    "        return [area1, area2, area3]\n",
    "        \n",
    "    def sample(self):\n",
    "        # Group selection\n",
    "        group_id = self._group_selection()\n",
    "        # Goal selection\n",
    "        goal = self._goal_selection(group_id)\n",
    "        \n",
    "        # Record sampled group and sampled goal for update()\n",
    "        self.sampled_group_id = group_id\n",
    "        self.sampled_goal = tuple(goal)\n",
    "        \n",
    "        # Increment the counter\n",
    "        self.t += 1\n",
    "        \n",
    "        return list(goal)\n",
    "    \n",
    "    def update(self, reward):\n",
    "        \"\"\"\n",
    "        Update the dictionary of reward information of the group and the goal\n",
    "        \n",
    "        Args:\n",
    "            reward (float): reward to the bandit\n",
    "        \"\"\"\n",
    "        # Update the sliding-window queue of selected information\n",
    "        if len(self.queue) == self.queue.maxlen:\n",
    "            pop_item = self.queue.popleft()\n",
    "            # Update dictionary\n",
    "            info = self.infos[('Group', pop_item['Group'])][('Goal', tuple(pop_item['Goal']))]\n",
    "            info['N'] -= 1\n",
    "            R = info['Q'].popleft()\n",
    "            assert R == pop_item['R']  # check if the correct value to be poped out\n",
    "        \n",
    "        # Record new information to the queue\n",
    "        self.queue.append({'Group': self.sampled_group_id, 'Goal': self.sampled_goal, 'R': reward})\n",
    "        # Update dictionary\n",
    "        info = self.infos[('Group', self.sampled_group_id)][('Goal', tuple(self.sampled_goal))]\n",
    "        info['N'] += 1\n",
    "        info['Q'].append(reward)\n",
    "        \n",
    "        # Clean the recorded sampled group id and goal\n",
    "        self.sampled_group_id = None\n",
    "        self.sampled_goal = None\n",
    "    \n",
    "    def _group_selection(self):\n",
    "        \"\"\"\n",
    "        Group selection\n",
    "        \n",
    "        Returns:\n",
    "            group_id (int): the index of the selected group\n",
    "        \"\"\"\n",
    "        if self.t < self.num_groups:  # initially linearly choose the group\n",
    "            group_id = self.t\n",
    "        else:\n",
    "            # TODO: two ways, either max of max Q, or max of average Q within the group\n",
    "            value_groups = []\n",
    "            for i in range(self.num_groups):\n",
    "                goal, Q = self._max_goal(i)\n",
    "                uncertainty = self._uncertainty(i, original=True)\n",
    "                value_groups.append(Q + uncertainty)\n",
    "                \n",
    "            group_id = np.argmax(value_groups)\n",
    "        \n",
    "        return group_id\n",
    "    \n",
    "    def _goal_selection(self, group_id):\n",
    "        \"\"\"\n",
    "        Goal selection within the group\n",
    "        \n",
    "        Args:\n",
    "            group_id (int): the index of the selected group\n",
    "            \n",
    "        Returns:\n",
    "            goal (tuple): selected goal\n",
    "        \"\"\"\n",
    "        if self.t < self.num_groups:  # initially uniformly sample the goal within the group\n",
    "            goals = self.groups[group_id]\n",
    "            idx = np.random.choice(range(len(goals)))\n",
    "            goal = goals[idx]\n",
    "        else:\n",
    "            goal, Q = self._max_goal(group_id)\n",
    "        \n",
    "        return goal\n",
    "    \n",
    "    def _max_goal(self, group_id):\n",
    "        \"\"\"\n",
    "        Returns the goal with max Q within the group\n",
    "        \n",
    "        Args:\n",
    "            group_id (int): ID of the group\n",
    "            \n",
    "        Returns:\n",
    "            goal (tuple or list): goal with max Q\n",
    "            Q (float): the Q associated with the goal\n",
    "        \"\"\"\n",
    "        info = self.infos[('Group', group_id)]\n",
    "        goals = []\n",
    "        Qs = []\n",
    "        for g, g_info in info.items():\n",
    "            goals.append(g[1])\n",
    "            if len(g_info['Q']) == 0:  # empty\n",
    "                Q_value = 0\n",
    "            else:\n",
    "                Q_value = np.mean(g_info['Q'])\n",
    "            Qs.append(Q_value)\n",
    "            \n",
    "        idx = np.argmax(Qs)\n",
    "        goal = goals[idx]\n",
    "        Q = Qs[idx]\n",
    "        \n",
    "        return goal, Q\n",
    "    \n",
    "    def _uncertainty(self, group_id, original=True):\n",
    "        \"\"\"\n",
    "        Calculate uncertainty term\n",
    "        \n",
    "        Args:\n",
    "            group_id (int): ID of the group\n",
    "            original (bool): If True, then use the original paper setting\n",
    "            \n",
    "        Returns:\n",
    "            uncertainty (float): uncertainty term of the given group\n",
    "        \"\"\"\n",
    "        if original:\n",
    "            c = self.D2*(self.D1)**(-self.gamma2/self.gamma1)\n",
    "            exponent = self.gamma2/(2*self.gamma1)\n",
    "            alpha = self.alphas[group_id]\n",
    "            ln = np.log(np.min([self.t, self.h]))\n",
    "            N = np.sum([info['N'] for info in self.infos[('Group', group_id)].values()])\n",
    "            \n",
    "            uncertainty = c*(alpha*(ln/N))**exponent\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        return uncertainty\n",
    "    \n",
    "    def _calculate_reward(self, agent_old, agent_new, env, config, goal):\n",
    "        \"\"\"\n",
    "        Calculate the learning progress signal as reward\n",
    "        \n",
    "        Args:\n",
    "            agent_old (Agent): deepcopy of agent before training\n",
    "            agent_new (Agent): agent after training\n",
    "            env (Env): environment\n",
    "            config (Config): configurations\n",
    "            goal (list or tuple): trained goal\n",
    "            \n",
    "        Returns:\n",
    "            reward (float): learning progress reward signal\n",
    "        \"\"\"\n",
    "        # Ensure the sampled goal is consistent \n",
    "        assert tuple(self.sampled_goal) == tuple(goal)\n",
    "        \n",
    "        # Set goal in the environment\n",
    "        env.get_source_env().goal_states = [goal]\n",
    "        \n",
    "        # Set max time steps as optimal trajectories (consistent with A* solution)\n",
    "        if config['use_optimal_T']:\n",
    "            T = get_optimal_steps(env)\n",
    "        else:\n",
    "            T = config['T']\n",
    "            \n",
    "        num_epi = 10\n",
    "        \n",
    "        # Create runners\n",
    "        runner_old = Runner(agent_old, env, config['gamma'])\n",
    "        runner_new = Runner(agent_new, env, config['gamma'])\n",
    "        \n",
    "        # Calculate value estimate\n",
    "        D_old = runner_old.run(T, num_epi)\n",
    "        D_new = runner_new.run(T, num_epi)\n",
    "        r_old = np.mean([np.sum(d['rewards']) for d in D_old])\n",
    "        r_new = np.mean([np.sum(d['rewards']) for d in D_new])\n",
    "        \n",
    "        reward = r_new - r_old\n",
    "        \n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         \n",
    "\n",
    "# Evaluate\n",
    "# Collect one batch of data from runner\n",
    "batch_data = self.runner.run(self.config['T'], self.config['eval_num_epi'])\n",
    "\n",
    "# Useful metrics\n",
    "batch_returns = [np.sum(data['rewards']) for data in batch_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class A(object):\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "a1 = A(2)\n",
    "\n",
    "old = deepcopy(a1)\n",
    "\n",
    "a1.val += 3\n",
    "\n",
    "print(a1.val)\n",
    "print(old.val)\n",
    "\n",
    "a1.val is old.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = SWUCBgGoalSampler(None, None)\n",
    "isinstance(a, SWUCBgGoalSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuo/anaconda3/envs/RL/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/zuo/anaconda3/envs/RL/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/zuo/anaconda3/envs/RL/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/zuo/anaconda3/envs/RL/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/zuo/anaconda3/envs/RL/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-98ef8c441c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/goal_selection.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/tmp.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-98ef8c441c37>\u001b[0m in \u001b[0;36mplotting\u001b[0;34m(log_file)\u001b[0m\n\u001b[1;32m     58\u001b[0m                        \u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                        \u001b[0mlog_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                        integer_x=True)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/lagom/lagom/core/plotter/plotter.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, title, xlabel, ylabel, xlim, ylim, log_x, log_y, integer_x, integer_y)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Plot the curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Plot uncertainty with shaded area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uncertainty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f069926bba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lagom.core.plotter import Plotter\n",
    "\n",
    "from goal_sampler import UniformGoalSampler\n",
    "from goal_sampler import RejectionGoalSampler\n",
    "from goal_sampler import RejectionAstarGoalSampler\n",
    "from goal_sampler import RejectionL2GoalSampler\n",
    "\n",
    "\n",
    "def get_data(IDs, logs):\n",
    "    data = []\n",
    "    for ID in IDs:\n",
    "        d = [i['Eval']['Mean success rate'] for i in logs[('ID', ID)].values()]\n",
    "        data.append(d)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def plotting(log_file):\n",
    "    # Create a plotter\n",
    "    plotter = Plotter()\n",
    "    \n",
    "    # Get the logging dictionary of goal selection\n",
    "    logs = np.load('logs/goal_selection.npy').item()['goal_selection']\n",
    "    \n",
    "    # Get IDs for different goal samplers, each with many random seeds\n",
    "    IDs_uniform = [logs['ID'] for logs in experiment.list_configs if logs['goal_sampler'] is UniformGoalSampler]\n",
    "    IDs_rejection = [logs['ID'] for logs in experiment.list_configs if logs['goal_sampler'] is RejectionGoalSampler]\n",
    "    IDs_rejection_astar = [logs['ID'] for logs in experiment.list_configs if logs['goal_sampler'] is RejectionAstarGoalSampler]\n",
    "    IDs_rejection_l2 = [logs['ID'] for logs in experiment.list_configs if logs['goal_sampler'] is RejectionL2GoalSampler]\n",
    "       \n",
    "    # Get metrics according to IDs\n",
    "    cover_uniform = get_data(IDs_uniform, logs)\n",
    "    cover_rejection = get_data(IDs_rejection, logs)\n",
    "    cover_rejection_astar = get_data(IDs_rejection_astar, logs)\n",
    "    cover_rejection_l2 = get_data(IDs_rejection_l2, logs)\n",
    "\n",
    "    # Add curves for each goal sampler\n",
    "    plotter.add_curve(cover_uniform, \n",
    "                      color='green', \n",
    "                      label='Uniform sampling', \n",
    "                      uncertainty=True,\n",
    "                      scales=[0.5, 1.0],  # stds\n",
    "                      alphas=[0.3, 0.2])  # transparency\n",
    "    \n",
    "    \n",
    "\n",
    "    title = 'Goal selection strategies in U-maze with REINFORCE'\n",
    "    xlabel = 'Goal iterations'\n",
    "    ylabel = 'Maze coverage (Optimal)'\n",
    "    xlim = [1, len(cover_uniform[0])]\n",
    "    ylim = [0, 1 + 0.05]\n",
    "    fig = plotter.plot(title, \n",
    "                       xlabel, \n",
    "                       ylabel, \n",
    "                       xlim=xlim, \n",
    "                       ylim=ylim, \n",
    "                       log_x=False, \n",
    "                       integer_x=True)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plotting('logs/goal_selection.npy')\n",
    "fig.savefig('logs/tmp.png')\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation of heatmaps (success coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from lagom.core.plotter import Plotter\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "path = 'logs/ID_0_eval_uniform.npy'\n",
    "info = 'Average Return over all goals'\n",
    "\n",
    "goals = [goal for iter_num, goal in np.load(path).item()[info].keys()]\n",
    "anim_data = list(np.load(path).item()[info].values())\n",
    "num_data = len(anim_data)\n",
    "\n",
    "map_size = 4\n",
    "\n",
    "def animate(i):\n",
    "    fig.clear()\n",
    "    \n",
    "    data = np.array(anim_data[i]).reshape([map_size, map_size])\n",
    "\n",
    "    ax = plotter.heatmap(data, \n",
    "                         vmin=0, \n",
    "                         vmax=1, \n",
    "                         cmap='YlGnBu', \n",
    "                         annot=True, \n",
    "                         linewidths=.0, \n",
    "                         square=True, \n",
    "                         xticklabels=np.arange(1, map_size+1), \n",
    "                         yticklabels=np.arange(1, map_size+1))\n",
    "    \n",
    "    ax.set_title('Training iteration: {},  goal: {}'.format(i, goals[i]))\n",
    "    \n",
    "    ax.add_patch(Rectangle(np.array(goals[i][::-1])-1, 1, 1, fill=False, edgecolor='yellow'))\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=num_data, interval=2000)\n",
    "\n",
    "anim.save('tmp.gif', writer='imagemagick', fps=.5)\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
